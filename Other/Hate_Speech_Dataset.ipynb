{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876a8181-ed5f-48ff-9be9-eef7f77f7b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import json\n",
    "import re\n",
    "from spacy.util import minibatch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bae9d2-4601-4736-b8d2-d09eab1c751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"speech_testing.txt\", 'rb')\n",
    "data = f.readlines()\n",
    "data_store = pd.DataFrame()\n",
    "data = [str(each).replace(\"\\'\", \"\").replace(\"\\\\n\", \"\")[1:] for each in data][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653c8222-19ba-4f30-a4f9-f83c0d503fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>You should know womens sports are a joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>You look like Sloth with deeper Downs syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>You look like Russian and speak like Indian. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Women deserve to be abused, I guess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Women are made for making babies and cooking d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>From the midnight sun where the hot springs blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>Dont say Im not your type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>And therefore never send to know for whom the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>And I cant stand another day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>All values, unless otherwise stated, are in US...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                            comment\n",
       "0             0           You should know womens sports are a joke\n",
       "1             1     You look like Sloth with deeper Downs syndrome\n",
       "2             2  You look like Russian and speak like Indian. B...\n",
       "3             3               Women deserve to be abused, I guess.\n",
       "4             4  Women are made for making babies and cooking d...\n",
       "..          ...                                                ...\n",
       "993         993   From the midnight sun where the hot springs blow\n",
       "994         994                          Dont say Im not your type\n",
       "995         995  And therefore never send to know for whom the ...\n",
       "996         996                       And I cant stand another day\n",
       "997         997  All values, unless otherwise stated, are in US...\n",
       "\n",
       "[998 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coms = []\n",
    "scores = []\n",
    "for each in range(len(data)):\n",
    "    elems = data[each].split(\";\")\n",
    "    coms.append(elems[0])\n",
    "    scores.append(1 if float(elems[1]) > 0.5 else 0)\n",
    "data_store[\"comment\"] = coms\n",
    "#data_store[\"comment\"].to_csv(\"trash.csv\")\n",
    "phonemized_ds = pd.read_csv(\"trash.csv\")\n",
    "#data_store[\"phonemized\"] = phonemized_ds[\"comment\"]\n",
    "data_store[\"score\"] = scores\n",
    "phonemized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa3f0e6-cfa8-4a62-bdeb-29ce0ade062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>phonemized</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You should know womens sports are a joke</td>\n",
       "      <td>juː ʃʊd noʊ wɪmɪnz spoːɹts ɑːɹ ɐ dʒoʊk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You look like Sloth with deeper Downs syndrome</td>\n",
       "      <td>juː lʊk laɪk slɑːθ wɪð diːpɚ daʊnz sɪndɹoʊm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You look like Russian and speak like Indian. B...</td>\n",
       "      <td>juː lʊk laɪk ɹʌʃən ænd spiːk laɪk ɪndiən boʊθ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women deserve to be abused, I guess.</td>\n",
       "      <td>wɪmɪn dɪzɜːv təbi ɐbjuːzd aɪ ɡɛs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women are made for making babies and cooking d...</td>\n",
       "      <td>wɪmɪn ɑːɹ meɪd fɔːɹ meɪkɪŋ beɪbiz ænd kʊkɪŋ dɪ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>And therefore never send to know for whom the ...</td>\n",
       "      <td>ænd ðɛɹfoːɹ nɛvɚ sɛnd tə noʊ fɔːɹ huːm ðə bɛl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>And I cant stand another day</td>\n",
       "      <td>ænd aɪ kænt stænd ɐnʌðɚ deɪ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>All values, unless otherwise stated, are in US...</td>\n",
       "      <td>ɔːl væljuːz ʌnlɛs ʌðɚwaɪz steɪɾᵻd ɑːɹ ɪn juːɛs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>negha you a little shit samurai</td>\n",
       "      <td>nɛɡhə juː ɐ lɪɾəl ʃɪt sæmjʊɹɹaɪ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>madarchod</td>\n",
       "      <td>mædɑːɹtʃɑːd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0             You should know womens sports are a joke   \n",
       "1       You look like Sloth with deeper Downs syndrome   \n",
       "2    You look like Russian and speak like Indian. B...   \n",
       "3                 Women deserve to be abused, I guess.   \n",
       "4    Women are made for making babies and cooking d...   \n",
       "..                                                 ...   \n",
       "994  And therefore never send to know for whom the ...   \n",
       "995                       And I cant stand another day   \n",
       "996  All values, unless otherwise stated, are in US...   \n",
       "997                    negha you a little shit samurai   \n",
       "998                                          madarchod   \n",
       "\n",
       "                                            phonemized  score  \n",
       "0              juː ʃʊd noʊ wɪmɪnz spoːɹts ɑːɹ ɐ dʒoʊk       1  \n",
       "1         juː lʊk laɪk slɑːθ wɪð diːpɚ daʊnz sɪndɹoʊm       1  \n",
       "2    juː lʊk laɪk ɹʌʃən ænd spiːk laɪk ɪndiən boʊθ ...      1  \n",
       "3                    wɪmɪn dɪzɜːv təbi ɐbjuːzd aɪ ɡɛs       1  \n",
       "4    wɪmɪn ɑːɹ meɪd fɔːɹ meɪkɪŋ beɪbiz ænd kʊkɪŋ dɪ...      1  \n",
       "..                                                 ...    ...  \n",
       "994  ænd ðɛɹfoːɹ nɛvɚ sɛnd tə noʊ fɔːɹ huːm ðə bɛl ...      0  \n",
       "995                       ænd aɪ kænt stænd ɐnʌðɚ deɪ       0  \n",
       "996  ɔːl væljuːz ʌnlɛs ʌðɚwaɪz steɪɾᵻd ɑːɹ ɪn juːɛs...      0  \n",
       "997                   nɛɡhə juː ɐ lɪɾəl ʃɪt sæmjʊɹɹaɪ       1  \n",
       "998                                       mædɑːɹtʃɑːd       1  \n",
       "\n",
       "[999 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.read_csv(\"bro_please_work.csv\")\n",
    "final_data = final_data.drop(['Unnamed: 0'], axis='columns')\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75e359c0-4583-4a01-a7d2-b8523f8cd4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 "
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "#nlp = en_core_web_md.load()\n",
    "textcat = nlp.create_pipe('textcat', config = {\"executive_classes\":True, \"architexture\":\"bow\"})\n",
    "nlp.add_pipe(textcat)\n",
    "\n",
    "textcat.add_label(\"no_hate\")\n",
    "textcat.add_label(\"hate\")\n",
    "\n",
    "train_text = final_data['phonemized'].values\n",
    "train_labels = [{'cats': {'no_hate' : label == 0, 'hate' : label == 1}} for label in final_data['score']]\n",
    "train_data = list(zip(train_text, train_labels))\n",
    "#random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for epoch in range(150):\n",
    "    losses = {}\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size = 10)\n",
    "    for batch in batches:\n",
    "        text, labels = zip(*batch)\n",
    "        nlp.update(text, labels, sgd = optimizer, losses = losses)\n",
    "    print(epoch+1, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd20139-a563-47ee-abd4-fb8732a11d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = input('Check hate: ')\n",
    "doc = [nlp.tokenizer(test_phrase)]\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(doc)\n",
    "predicted_label = scores.argmax(axis=1)\n",
    "[textcat.labels[label] for label in predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0908129-33bb-44fb-81bb-a7b09d6543e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Check hate:  haɪ fɹɛnd wʌts ʌp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['no_hate']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misspelled_n_word_and_one_normal = ['fɑːk juː naɪə ', 'fʌk juː nɛɡhə ', 'fʌk juː nɪɡə ', 'juː sænd nɪɡɚ ', 'juː lɪɾəl naɪɑːɹ ', 'fɑːk juː ɡeɪ æs ', 'haɪ fɹɛnd wʌts ʌp ', 'fɑːk juː ']\n",
    "test_phrase = input('Check hate: ')\n",
    "doc = [nlp.tokenizer(test_phrase)]\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(doc)\n",
    "predicted_label = scores.argmax(axis=1)\n",
    "[textcat.labels[label] for label in predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbec263c-1a22-4666-b34f-74ee210eae9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 "
     ]
    }
   ],
   "source": [
    "nlp2 = spacy.blank('en')\n",
    "textcat_new = nlp2.create_pipe('textcat', config = {\"executive_classes\":True, \"architexture\":\"bow\"})\n",
    "nlp2.add_pipe(textcat_new)\n",
    "\n",
    "textcat_new.add_label(\"no_hate\")\n",
    "textcat_new.add_label(\"hate\")\n",
    "\n",
    "train_text = final_data['comment'].values\n",
    "train_labels = [{'cats': {'no_hate' : label == 0, 'hate' : label == 1}} for label in final_data['score']]\n",
    "train_data = list(zip(train_text, train_labels))\n",
    "#random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp2.begin_training()\n",
    "\n",
    "for epoch in range(160):\n",
    "    losses = {}\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size = 10)\n",
    "    for batch in batches:\n",
    "        text, labels = zip(*batch)\n",
    "        nlp2.update(text, labels, sgd = optimizer, losses = losses)\n",
    "    print(epoch+1, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a021c7e8-f670-451a-8b91-a05d67cc779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Check hate:  you little nigger\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.11976375, 0.9333883 ]], dtype=float32), ['hate'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = input('Check hate: ')\n",
    "doc = [nlp2.tokenizer(test_phrase)]\n",
    "textcat = nlp2.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(doc)\n",
    "predicted_label = scores.argmax(axis=1)\n",
    "scores, [textcat.labels[label] for label in predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2098039-c05f-41aa-b44f-95ab1aaad5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('chat.json', 'r')\n",
    "data = f.read().replace('\\n', '')\n",
    "cleaned_data = json.loads(data)\n",
    "messages = {}\n",
    "temp = {'Author':[], 'Message':[]}\n",
    "test_set = pd.DataFrame(temp)\n",
    "pattern = \"reacted *.* to your message\"\n",
    "for each in cleaned_data['messages']:\n",
    "    if 'content' in each.keys():\n",
    "        sender = each['sender_name']\n",
    "        msg = each['content']\n",
    "        if sender in messages and 'an att' not in msg and 'liked a message' not in msg and not re.search(pattern, msg):\n",
    "            messages[each['sender_name']].append(msg)\n",
    "            test_set.loc[len(test_set.index)] = [sender, msg]\n",
    "        elif 'an att' not in msg and 'liked a message' not in msg and not re.search(pattern, msg):\n",
    "            messages[sender] = [msg]\n",
    "            test_set.loc[len(test_set.index)] = [sender, msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e170f2bc-5411-45f8-87fe-a45c4684d1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaustubh Joshi</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>Murica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaustubh Joshi</td>\n",
       "      <td>ð¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>ð«ð¤ ðð¦",
       "ðºð¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>ð¤«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>Lord and 4th roommate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>Kartikay Sankhdher</td>\n",
       "      <td>Where</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>Kaustubh Joshi</td>\n",
       "      <td>Abe tu to bola sab chhodke jars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>Tabhi to summer ka bhi kiraya diya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8077</th>\n",
       "      <td>Puneet Bajaj</td>\n",
       "      <td>Ham log wahi reh rahe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8078 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author                             Message\n",
       "0         Kaustubh Joshi                                   $\n",
       "1           Puneet Bajaj                              Murica\n",
       "2         Kaustubh Joshi                                ð¤\n",
       "3           Puneet Bajaj            ð«ð¤ ðð¦\n",
       "ðºð¸\n",
       "4           Puneet Bajaj                                ð¤«\n",
       "...                  ...                                 ...\n",
       "8073        Puneet Bajaj               Lord and 4th roommate\n",
       "8074  Kartikay Sankhdher                               Where\n",
       "8075      Kaustubh Joshi     Abe tu to bola sab chhodke jars\n",
       "8076        Puneet Bajaj  Tabhi to summer ka bhi kiraya diya\n",
       "8077        Puneet Bajaj               Ham log wahi reh rahe\n",
       "\n",
       "[8078 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad88855-657a-4a1c-a8f2-0a5affc2cbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for test_phrase in test_set['Message']:\n",
    "    doc = [nlp2.tokenizer(test_phrase)]\n",
    "    textcat_bro = nlp2.get_pipe('textcat')\n",
    "    scores, _ = textcat_bro.predict(doc)\n",
    "    predicted_label = scores.argmax(axis=1)\n",
    "    res.append([textcat_bro.labels[label] for label in predicted_label][0])\n",
    "    print(test_set['Author'][test_set['Message'] == test_phrase].values[0]+\":\", test_phrase + \" ||| intent:\", res[-1], scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f9016a-eb42-4e8a-95b3-e8f65c0e2916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WE NEED THE NAZI PARTY TO RETURN.....GET ANOTHER HITLER...AND FORM THE SS....AND START AN ETHNIC CLEANSING OF ALL MUSLIMS...YES YES..GATHER THEM UP...PUT THEM IN A CONCENTRATION CAMP...THEN PUT THESE MUSLIM REFUGEES ON A SHIP AND SEND THEM ALL BACK TO THIER OWN COUNTRIES ....AND THEY CAN DO AS THEY WANT THERE...LIVE THIER WAYS AND BY THIER RIDICULOUS LAWS.... THEY DONT ASSIMILATE TO THE NEW WESTERN COUNTRIES..AND TRY TO DICTATE TO US WHAT TO DO AND TO EVEN REMOVE JESUS FROM SCHOOLS AND OTHER PUBLIC AREAS...ARE YOU FUCKING SERIOUS...FUCK OFF YOU DIRTY SMELLING MUSLIMS... STOP DICTATING WHAT WE CAN OR CANT DO IN OUR OWN COUNTRIES...PEOPLE POWER MUST RISE AND SAY ENOUGH IS ENOUGH...TAKE SWEDEN BACK FOR SWEDES...TAKE GREECE BACK FOR GREEKS..TAKE GERMANY BACK..TAKE POLAND BACK..TAKE DENMARK BACK...SAVE OUR COUNTRIES....AND TAKE EUROPE BACK. INTRODUCE AN...SS...STYLE POLICE...AND CLEAN UP THESE STREETS AND GHETTOS....FULL OF DIRTY MUSLIMS...ITS THE GOVERNMENTS FAULT FOR ALLOWING THS SHIT TO HAPPEN....SEND THE MILITARY IN..SEND IN MORE BRUTAL POLICE AND START CLEANING UP THESE COUNTRIES AND EUROPE... MUSLIMS ARE INVADING EUROPE AND WE ARE ALLOWING THIS TO HAPPEN. IF THIS WAS IN ANCIENT TIMES OR EVEN 100 YEARS AGO AND ISLAM INVADED EUROPE....IT WOULD BE AN ALL OUT WAR. BRING BACK THE CRUSADERS AND NAZI POLICE.  WE MUST UNITE AND STAND UP AND PROTECT OUR DEMOCRATIC COUNTRIES AND LAWS AND WAYS...AND ELIMINATE ISLAM AND THROW THESE DIRTY  SMELLING MUSLIM...ANIMALS OUT AND SEND THEM BACK TO THEIR OWN COUNTRIES AND THEY CAN LIVE AS THEY WISH..THEY CAN FUCK THEIR GOATS AND RAPE THEIR OWN WOMEN..  FUCKING DISGUSTING MUSLIMS...LOW LIFE DIRTY RACE...AND ISLAM IS NIT GODS RELIGION...ITS A CULT..ITS A RIDICULOUS UNETHICAL AND IMORAL CULT..! ITS SATINS WORK..SATINS PREACHINGS.   GOD..THE CREATOR OF THE UNIVERSE....DOES NOT PREACH TO KILL INFIDELS AND KILL NON BELIEVERS... AND TO HAVE 3...4...5 WIVES AND COMMIT PEDOPHILIA..AND MARRY 9 YEAR OLD LITTLE GIRLS..!  MUSLIMS....WHO HAVE NEVER CONTRIBUTED TO HUMANITY....NEVER INVENTED ANYTHING ....NOTHING POSITIVE COMES FROM ISLAM...THEY CREATED NOTHING..INVENTED NOTHING...CONTRIBUTED NOTHING TO THE HUMAN RACE.... MUSLIMS, JUST LIVE IN OUR WESTERN DEMOCRATIC COUNTRIES...ENJOY OUR WAYS ..MILK THE WELFARE SYSTEM...AND RUIN THESE COUNTRIES...CREATE PROBLEMS...FIGHT...STEAL AND CREATE CRIME...SCARE PEOPLE...TR6 TO CHAGE OUR WESTERN WAY OF LIFE AND EVEN RAPE OUR WOMEN..  FUCK THESE COCKSUCKERS...BURN THEM ALL...IMPALE THEM...WE MUST FIGHT BACK AND UNITE AND CLEAN EUROPE UP AGAIN. SOON GOD WILL SEND HIS TRUE MESSENGER....TO PLANET EARTH .GOD WILL SEND A CLEAR MESSAGE ...TO HUMANITY AND THE MUSLIM PEOPLE ...WILL FEEL THE WRATH OF GOD AND SUFFER THE CONSEQUENCES....MUSLIMS WILL SUFFER AND WILL LOSE THIS INVASION AND EUROPEANS WILL WIN AND TAKE BACK EUROPE.. This is the beginning of the new CRUSADES...Christianity vs Islam...the crusaders against Islam and we need to fight and protect our way of life and Democratic society'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"comment\"][21]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
